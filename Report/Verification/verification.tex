%mainfile: ../master.tex
\chapter{Test and Verification}
This section contains a description of the testing, performed on the system to verify that it, to a satisfying degree, solves the problem solution. Along with this description, a number of alternatives will be discussed in relation to why they were not chosen.

\section{Methodology}
To test the system, we set up a simple test system in a controlled environment, consisting of just one sensor an emulatable action and the server. Here the system is exposed to deliberate patterns, designed to test the ability to learn, timing and adaptability of the system. A pattern here consisting of an action and a specific sequence of states. The patterns were performed until the system took over and performed the actions accordingly to the patterns performed, at which test would be considered successful, or until the confidence of the reasoner did not change in a positive direction for the given pattern. This is a simple test, but it shows that our system can recognise a pattern, which was deemed to be the smallest requirement for the system to be working properly.

For testing whether the system satisfies the deadline of 100 ms\cref{sub:people} from a states is read from the sensors till an action is performed, a timer is embedded in code of the sensor station. The timer starts at read and stops at acting, doing this multiple times and averaging of the resulting timings, gives us an indication of the average time it takes to respond to some interaction. This is not however the worst case execution time of the system, some theoretical worst case analysis of the communication\cref{sec:xbee} and the embedded subsystem\cref{sub:sensorStation}, but the embedded subsystem this requires a much deeper theoretical analysis of the scheduler acting on platform the embedded subsystem is present on.

Once verified that the system can learn a usage pattern, reason and subsequently perform the appropriate action for a given pattern within deadline, the second key component of the system is tested, the ability to adapt to change in the patterns. After the system had learned a pattern, a different overlapping pattern is performed, until the system adapts to it, the rate at which the system adapts is negligible in the sense that the rate at which the system learn is open to modification.
\section{Results}
\input{Verification/tests.tex}

\section{Alternative tests}
The first alternative which were considered is a real world use case. In this test a system would be setup in one or more users homes for a given set of time. Once the test had finished the log data from the system along with user testimony would determine the performance of the system. This test is time consuming, because the system would need to be live for an extended period of time to learn user patterns on a daily, weekly, or longer scale. The log data can also be difficult and time consuming to analyse because the large amount of data processed by the system and the difficult to visually represent machine learning model used.
\\\\
Unit tests is another alternative which ensures some stability in the system. But for a system that relies on random data with patterns, which is difficult to produce programmatically, unit tests does not show how well the system performs only that it produces some data. A preliminary unit test were performed on the system. In this test the system were given a specific set of sensor states a set number of times and then checked whether the system produced the expected action given a sensor state.
