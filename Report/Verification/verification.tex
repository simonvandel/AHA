%mainfile: ../master.tex
\chapter{Test and Verification}
In this section a description of the testing performed on the system to verify that it, to a satisfying degree, solves the problem solution. Along with this description a number of alternatives will also be discussed in relation to why they were not chosen.

\section{Methodology}
To test the system, we set up a simple test system in a controlled environment, consisting of just one sensor an emulatable action and the server. Here the system is exposed to deliberate patterns, designed to test the learning, timing and adaptability of the system. A pattern here consisting of an action and a change in the sensor state. The patterns were performed until the system took over and performed the actions accordingly to the patterns, at which test be considered would be considered successful, or until the confidence of the AI subsystem did not change in a positive direction for the given pattern. This is a simple test, but it shows that our system can recognise a pattern which is deemed to be the smallest requirement for the system to be working properly.

For testing whether the system satisfies the deadline of 100ms\cref{sub:people} from a sensor read till an action is performed, a timer is embedded in code of the sensor station. The timer starts at read and stops at acting, doing this multiple times and average of the resulting timings, gives us an indication of the average time it takes to respond to some interaction. This is not however the worst case timing of the system, some theoretical worst case analysis of the communication\cref{sec:xbee} and the sensor station code\cref{sub:sensorStation}, but the AI subsystem this requires a much deep theoretical analysis of the scheduler acting on platform the subsystem the AI subsystem is present on.

Once verified that the system can learn a usage pattern, reason and subsequently perform the appropriate action for a given pattern within deadline, the second key component of the system is tested, the ability to adapt to a change in patterns. After the system had learned a pattern, a different overlapping pattern were performed, until the system adapted to it, the rate at which the system adapt is negligible in that the rate at which the system learn is open to modification.
\section{Results}
%gogo write stuff

\section{Alternative tests}
The first alternative which were considered is a real world use case. In this test a system would be setup in one or more users homes for a given set of time. Once the test had finished the log data from the system along with user testimony would determine the performance of the system. This test is time consuming, because the system would need to be live for an extended period of time to learn user patterns on a daily, weekly, or longer scale. The log data can also be difficult and time consuming to analyse because the large amount of data processed by the system and the difficult to visually represent machine learning model used.
\\\\
Unit tests is another alternative which ensures some stability in the system. But for a system that relies on random data with patterns, which is difficult to produce programmatically, unit tests does not show how well the system performs only that it produces some data. A preliminary unit test were performed on the system. In this test the system were given a specific set of sensor states a set number of times and then checked whether the system produced the expected action given a sensor state.
