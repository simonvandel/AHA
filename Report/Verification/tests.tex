All the logs can be found in \cref{app:cd}. \ranote{remember to put the logs on the CD}
\subsubsection{Single pattern test}
The setup consisted of a single sensor station with two switches. The switches were connected to  Light-Emitting Diodes (LED) such that each switch controlled one LED. The pattern being performed; when turning on one LED the other one is turned on as well. A snippet of the samples this produced can be seen in \cref{Table:SampleSnippet}, where time moves from right to left so the rightmost state is the newest.
\begin{center}

\begin{table}[htbp]
  \centering
  \begin{tabular}{c c c c c c}
    \toprule
    Sample & & & & &  \\ \midrule
    1 & 1 & 3 & 2 & 0 & 1 \\
    2 & 3 & 2 & 0 & 1 & 3 \\
    3 & 2 & 0 & 1 & 3 & 2 \\
    4 & 0 & 1 & 3 & 2 & 0 \\
    5 & 1 & 3 & 2 & 0 & 1 \\
    6 & 3 & 2 & 0 & 1 & 3 \\
    7 & 2 & 0 & 1 & 3 & 2 \\
    8 & 0 & 1 & 3 & 2 & 0 \\
    9 & 1 & 3 & 2 & 0 & 1 \\
     \\ \bottomrule
  \end{tabular}
  \caption{Samples from test with simple pattern, as performed by the user}
\end{table}

\label{Table:SampleSnippet}
\end{center}
Once 31 samples had been received, as can be seen in a snippet from the learner log\cref{Listing:MarkovGenLog}, the learner were run and a model generated.
\lstset{language=xml}
\begin{lstlisting}[label = Listing:MarkovGenLog, caption = Snippet of log from model generation]
  <date>2015-12-17T09:03:32</date>
  <logger>aiLogger</logger>
  <message>Sample size for generating hidden markov model: 34</message>
\end{lstlisting}
With this model the system started trying to predict actions. At this point no user actions were being performed on sensor id 1. The confidence threshold for this test were 75\%. The log trace for the first action can be seen in \cref{Listing:CompletActionTrace}. And as can be seen the in the logs the system predicted the state at 09:03:36 based on the state from 09:03:33. Looking at the logs beforehand that shows user actions, it can be seen that this pattern was repeated by the user.
\begin{lstlisting}[label = Listing:CompletActionTrace, caption = Snippets from different logs to show how the process of making an action]
	<record>
	  <date>2015-12-17T09:03:33</date>
	  <millis>1450339413544</millis>
	  <logger>sampleLogger</logger>
	  <thread>1</thread>
	  <message>Sample:  3 2 0 1 3</message>
	</record>
	
	<record>
	  <date>2015-12-17T09:03:33</date>
	  <millis>1450339413553</millis>
	  <logger>aiLogger</logger>
	  <thread>1</thread>
	  <message>Confidence: 0.8668783888317774. Actions: 
	Set sensor id 1 to value 0</message>
	</record>
	
	<record>
	  <date>2015-12-17T09:03:33</date>
	  <millis>1450339413555</millis>
	  <logger>reasonLogger</logger>
	  <thread>1</thread>
	  <message>Sending data: Set sensor id 1 to value 0</message>
	</record>
	
	<record>
	  <date>2015-12-17T09:03:36</date>
	  <millis>1450339416153</millis>
	  <logger>sampleLogger</logger>
	  <message>Sample:  2 0 1 3 2</message>
	</record>
\end{lstlisting}
Based on this it can be concluded that the system successfully learned and imitated a pattern.

\subsubsection{Real Time Test}
To perform this test the system were first taught a simple pattern as it were important, that a certain action on the arduino forced a prediction of an action by the server model. A separate button were added that had no other function then to start the test (ie. it were not part of the pattern). This allowed the test code to artificially create an action on the other button and then immediately start a timer. The button were then disabled as to avoid restarting the timer. Then once the arduino received the action the timer were stopped and the time for a full loop of the system were found. One thing to note, this time can vary depending on when in the arduino loop the button were pressed. To document this two tests were performed one were the artificial button press happened at the theoretically best time and one at the theoretically worst time. The worst case happens when we perform the button press after we send a state to the server but before we start receiving data. This means we have to wait for the receiving delay, then send again, and then wait for the receive delay again. For the best case test, the lowest observed time were 140ms\ranote{insert actual test}, which is 40ms above the deadline. This could be attributed to the send and receive of the xbee modules which in practical testing showed a delay of up to 60ms for one send, however theoretically the worst case should be 50ms\cref{xbee_latency}. This variance could be due to a number of things, eg. cheap hardware or non-optimally implementation. For each other separate module we have the approximate time, and so an average case for a full loop of the system would be 155 as seen in \cref{Table:RunTimeAprox}.
\begin{center}
	\begin{table}[htbp]
	  \centering
	  \begin{tabular}{c | c}
		\toprule
		Sample  		& 			\\ \midrule
		Test Start		&
		encode 			& <2ms  	\\
		send   			& <50  		\\
		Reason loop 	& avg: 53 	\\
		Receive 		& <50  		\\
		Total			& 155		\\
									\\ \bottomrule
	  \end{tabular}
	  \caption{An approximation of run time of each separate module, from single pattern test. When performing an action at the optimal time in the arduino loop}
	\end{table}
 \label{Table:RunTimeAprox}
\end{center}
The test for the worst case test, were .... best case and worst case.
The average case for this test can be seen in \creft{Table:WorstRunTimeAprox}

\begin{center}
	\begin{table}[htbp]
	  \centering
	  \begin{tabular}{c | c}
		\toprule
		Sample  		& 			\\ \midrule
		encode 			& 		  	\\
		Test Start		&			\\
		send   			& <50  		\\
		Reason loop 	& avg: 53 	\\
		Receive 		& <50  		\\
		encode 			& <2ms  	\\
		send   			& <50  		\\
		Reason loop 	& avg: 53 	\\
		Receive 		& <50  		\\
		Total			& 308		\\
									\\ \bottomrule
	  \end{tabular}
	  \caption{An approximation of run time of each separate module, from single pattern test. When performing an action at the worst time in the arduino loop}
	\end{table}
 \label{Table:WorstRunTimeAprox}
\end{center}








