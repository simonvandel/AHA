All the logs can be found in \cref{app:cd}.
\subsubsection{Single Pattern Test}\label{subsec:singlePatternTest}
The set up consisted of a single sensor station with 3 switches. The switches were connected to LEDs, such that each switch controlled one LED. The pattern being performed is XOR. 2 switches represents the boolean values for the XOR function, and the last switch, which is emulatable by the system, represents the result of applying XOR to the value of the two switches.

A snippet of the samples this test produced can be seen in \cref{Table:SampleSnippet}, where time moves from left to right so the rightmost state is the most recent.
\begin{center}

\begin{table}[htbp]
  \centering
  \begin{tabular}{c c c c c c c c c c c}
    \toprule
    Sample & & & & & & & & & &  \\ \midrule
           1 & 7 & 11 & 10 & 6 & 8 & 12 & 13 & 9 & 7 & 11 \\
           2 & 11 & 10 & 6 & 8 & 12 & 13 & 9 & 7 & 11 & 10 \\
           3 & 10 & 6 & 8 & 12 & 13 & 9 & 7 & 11 & 10 & 6 \\
           4 & 6  & 8 & 12 & 13 & 9 & 7 & 11 & 10 & 6 & 7 \\
           5 & 8 & 12 & 13 & 9 & 7 & 11 & 10 & 6 & 7 & 11 \\
           6 & 12 & 13 & 9 & 7 & 11 & 10 & 6 & 7 & 11 & 13 \\
           7 & 13 & 9 & 7 & 11 & 10 & 6 & 7 & 11 & 13 & 9 \\
           8 & 9 & 7 & 11 & 10 & 6 & 7 & 11 & 13 & 9 & 8 \\
           9 & 7 & 11 & 10 & 6 & 7 & 11 & 13 & 9 & 8 & 6 \\
           10& 11 & 10 & 6 & 7 & 11 & 13 & 9 & 8 & 6 & 10 \\
           11 & 10 & 6 & 7 & 11 & 13 & 9 & 8 & 6 & 10 & 6
     \\ \bottomrule
  \end{tabular}
  \caption{Samples from test with simple pattern, as performed by the user}\label{Table:SampleSnippet}
\end{table}
\end{center}
Once 32 samples had been received, as can be seen in a snippet from the ai log \cref{Listing:MarkovGenLog}, the learner was run and a model generated.

\lstset{language=xml}
\begin{lstlisting}[label = Listing:MarkovGenLog, caption = Snippet of log from model generation]
  <date>2015-12-17T20:13:01</date>
  <millis>1450379581194</millis>
  <logger>aiLogger</logger>
  <message>Sample size for generating hidden markov model: 32</message>
\end{lstlisting}

With this model, the system started trying to predict actions. At this point, no user actions were being performed on sensor id 1. The confidence threshold for this test was 60\% and the history were 9 (meaning a scope consisted of 10 samples). The log trace for the first action can be seen in \cref{Listing:CompletActionTrace}. As can be seen in the logs, the system predicted the state at 20:13:07, based on the state from 20:13:04. Looking at the logs before that, shows user actions; it can be seen that this pattern was repeated by the user.

\begin{lstlisting}[label = Listing:CompletActionTrace, caption = Snippets from different logs to show how the process of making an action]
    <record>
        <date>2015-12-17T20:13:04</date>
        <millis>1450379584477</millis>
        <logger>sampleLogger</logger>
        <thread>1</thread>
        <message>Sample: 9 8 6 10 6 7 9 7 11 13</message>
    </record>

    <record>
        <date>2015-12-17T20:13:04</date>
        <millis>1450379584601</millis>
        <logger>aiLogger</logger>
        <thread>1</thread>
        <message>Confidence: 0.6542340925943608. Actions:
            Set sensor id 2 to value 1</message>
    </record>

    <record>
        <date>2015-12-17T20:13:04</date>
        <millis>1450379584601</millis>
        <logger>reasonLogger</logger>
        <message>Sending data: Set sensor id 2 to value 1</message>
    </record>

    <record>
        <date>2015-12-17T20:13:07</date>
        <millis>1450379587647</millis>
        <logger>sampleLogger</logger
        <message>Sample: 8 6 10 6 7 9 7 11 13 9</message>
    </record>
\end{lstlisting}

Based on this it can be concluded that the system successfully learned and imitated a pattern.

\subsubsection{Deadline Test}
To perform this test, the system was first taught the XOR pattern, as it was important that the system could predict an action during the test. A button was added, that had no other function than to start the test. This allowed the test code to artificially create an action on the button and then immediately start a timer. The button was then disabled, in order to avoid restarting the timer. Then, once the embedded subsystem received the action, the timer was stopped, and the time for a full loop of the system was found. One thing to note is that this time can vary, depending on when in the embedded subsystem's loop, the button was pressed.

To document this, two tests were performed; one, where the artificial button press happened at the theoretically optimal order, and one at the theoretically worst order. The worst case happens when we perform the button press right about we have read the sensors. This means that we have to wait a full cycle of processing the old sensor values, before reading the new sensor sensor values and processing those.

As can be seen below, the system does not uphold the deadline. This could be attributed to the sending and receiving times of the XBee modules which, in practical testing, showed a delay of up to 60 ms for one send, however, theoretically, the worst case should be 50 ms\cite{xbee_latency}. This variance could be due to a number of things, for example cheap hardware or a non-optimal implementation. The average time spent in the learning subsystem for both the simple pattern test and the deadline test, was 52.5 ms. This was found by averaging over all runs described in the logs that can be found in \cref{app:cd}.

For the optimal case test, the lowest observed time was 122 ms, which is 22 ms above the deadline. For each separate module, we have the approximate running time, and so an approximation of a worst case full loop of the system would be 190 ms as seen in \cref{Table:RunTimeAprox}.

\begin{center}
	\begin{table}[htbp]
	  \centering
	  \begin{tabular}{l l}
		\toprule
		Position in loop		& Run Time  \\ \midrule
		Test Start		        & 0 ms         \\ \midrule
		Encode 			        & <2 ms  	\\ \midrule
		Send   			        & <50 ms     \\ \midrule
		Learner loop 	        & <88 ms     \\ \midrule
		Receive 		        & <50 ms     \\ \midrule \midrule
		Total			        & <190 ms	    \\
                                            \bottomrule
	  \end{tabular}
	  \caption{An approximation of a worst case run time of each separate module, when performing an action at the optimal time in the Arduino loop.}\label{Table:RunTimeAprox}
	\end{table}
\end{center}

The best observed run time, in the worst case test, was 268 ms. The approximation of a worst case, full loop of the system, in this situation would be 378 ms as seen in \cref{Table:WorstRunTimeAprox}

\begin{center}
	\begin{table}[htbp]
	  \centering
	  \begin{tabular}{l l}
		\toprule
		Position in loop		& Run Time  \\ \midrule
		Encode 			        & 0  	  	\\ \midrule
		Test Start		        & 0  		\\ \midrule
		Send   			        & <50 ms     \\ \midrule
		Learner loop 	        & <88 ms     \\ \midrule
		Receive 		        & <50 ms     \\ \midrule
		encode 			        & <2 ms      \\ \midrule
		send   			        & <50 ms     \\ \midrule
		Learner loop 	        & <88 ms	    \\ \midrule
		Receive 		        & <50 ms     \\ \midrule \midrule
		Total			        & <378 ms     \\
                                            \bottomrule
	  \end{tabular}
	  \caption{An approximation of a worst case run time of each separate module, when performing an action at the worst time in the Arduino loop.}\label{Table:WorstRunTimeAprox}
	\end{table}
\end{center}

These tests show that the system has a certain risk of exceeding the deadline, by up to 278 ms. So even though the system can get close to the deadline, in a best case upholding it, it cannot be guaranteed. However according to \cite{jakobnielsen} exceeding the deadline by 278 ms would still not cause any annoyance to the user, since the time is unnoticeable.

\subsubsection{Adaption Test}
In this test, the adaptation of the system was tested. The system should be able to change patterns and take feedback from the user. First, the XOR pattern, as described in \cref{subsec:singlePatternTest}, was learned. After this, the test conductor tried to override this, with an AND pattern. This resulted in him inverting the actions, as can be seen in \cref{Table:userPatternChange}. This should be read as what the system is currently enforcing on the left side of the arrow, and what the test conductor would enforce on the system on the right side of the arrow. This results in the test conductor inverting the action of the system in three of the cases, and only leaving one case (0,0) left as it is.

\begin{table}[htbp]
\begin{center}
  \begin{tabular}{| c | c | c |}
    \hline
        & 0                 & 1                 \\ \hline
      0 & $0 \rightarrow 0$ & $1 \rightarrow 0$ \\ \hline
      1 & $1 \rightarrow 0$ & $0 \rightarrow 1$ \\
    \hline
  \end{tabular}
  \caption{Table illustrating change in the users pattern}\label{Table:userPatternChange}
\end{center}
\end{table}
In this test, the confidence threshold for the system was adjusted to 60\% and the history was of size 3.
Some errors were found with the feedback method. When the system got feedback on an action, it did not correctly lower the probability for that action, meaning the action continued to happen. The method did also not always register feedback from the user, due to errors in the timing of the AI subsystem.

It was found that the system was better at finding emerging patterns, as opposed to adapting to new patterns. This makes sense, when considering how the learning and reasoning has been implemented. The Baum-Welch algorithm has been created to find emerging patterns in data. Normally, the problem domain is not aware that it is being monitored, and a change in pattern will only be shown indirectly, through a change in the patterns of the problem domain. The system's preference would only change, when the amount of proofs for the new patterns exceeded that of the old pattern. In this case the user is able to explicitly give feedback to the system. This should result in the right probabilities being lowered enough so the next time the pattern happens the action should not be conducted by the system. It was not possible for the group to find an already known algorithm for this due to the specificness of the problem. This feedback were therefore implemented from logic. The principle is working for adapting but the tweaking is off, resulting in the system adapting a too slowly.

However, based on this test it cannot be concluded how the system would perform, when deployed in a real world setting, as the amount of data would be significantly larger, as well as the patterns likely being more complex.
