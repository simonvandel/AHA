%mainfile: ../master.tex
\section{Normaliser}
\label{sec:normaliser}
The purpose of the normaliser is to reduce the domain of sensor values, such that the number of states is reduced, as well as to eliminate noise from the sensor values. The normalisation process consists of two parts. The first part of the normaliser is responsible for clustering the data, using the method known as the elbow method, described in \cref{sub:elbow_method}. The second part is responsible for optimisation of these clusters. The optimisation is done to even out deviations, and thereby increase the accuracy of the clusters by eliminating hard breaks. The second part can be achieved using a method known as Jenks natural breaks optimisation, described in \cref{sub:jenks}.

\subsection{The Elbow Method}
\label{sub:elbow_method}
The elbow method uses the variance of each cluster of sensor values to determine how many clusters are the optimal amount. The idea can be described as follows:
\begin{enumerate}
\item Start with $k$ number of clusters, where $k>0$
\item Calculate the variance of the clusters
\item Increase $k$ until the percentage difference in variance is below some given threshold.
\end{enumerate}
The variance of each cluster is calculated and compared across the clusters. The variance of a cluster is calculated as follows:
Let $(x_1,x_2,x_3,...x_i)$ be a cluster.
\\\\Then the variance $\sigma$ is found as such
$$\sigma^2 = \frac{\displaystyle\sum_{i = 1}^{n}(x_{i}-\overline{x})^2 }{n} \Biggr\rvert\ \overline{x}  =\frac{\displaystyle\sum_{i=1}^{n}x_{i}}{n},\ n =\text{number of all elements in a cluster} ,$$
$$ x_{i} = i_{th} \text{ element in a cluser} $$
\\\\
Once $\sigma^2$ is found for the existing clusters, the data is split up into $k+1$ new clusters and the variance for this set of clusters is calculated. If the calculated variance has a greater percent variance than some threshold, the process is repeated with the starting number of clusters being $k+1$. If the percent variance is lower than the threshold then it means that the right amount of clusters is reached.
\subsection{Jenks' Natural Breaks Optimisation}
\label{sub:jenks}
When the number of clusters have been determined, another method is used to optimise the distribution of the data within the specified clusters. This method uses the squared sum of deviations within clusters, as well as the squared sum of deviations from the average, to determine fitness for the data. The fitness describes, how well the data fits within the clusters.
\\\\
The method can be described in the following four steps.
\begin{enumerate}
  \item Calculate squared sum of deviations for each cluster, $C$
  \item Calculate squared sum of deviations from array mean, $M$
  \item Subtract $C$ from $M$, this will give $MC$.
  \item After inspecting $C$ for every cluster, then move units from the cluster with the largest $C$ value towards the cluster with the lowest $C$.
\end{enumerate}
In the first step, the squared sum of deviations for each cluster is calculated. The deviation is a measure of how far away a certain point, in the data set, is from the mean. Where the mean is $\overline{x}$. Since the deviation is $(x_i-\overline{x})$, the sum of squared must be $$C= \displaystyle\sum_{i=1}^{n}(x_i-\overline{x})^2$$

The second step is almost identical to the first step. The difference is that the mean is calculated from the entire collection, instead of the clusters. The only modifications would be to change $\overline{x}$.
\\\\
The third step is quite self-explanatory and consists of a basic arithmetic operation; $MC = M-C$. The result of this step is however used later on in the method.
\\\\
When all the calculations are done, the existing clusters are inspected and the $C$ value is taken into consideration. Since the clusters are sorted in ascending order, the top element from the cluster with the largest $C$ value is moved toward a cluster with the lowest $C$ value. After this rearrangement the $C$ value for every cluster is recalculated. The process is repeated and for each repetition the fitness of the data is measured.


As aforementioned, fitness describes how well data fits into a cluster. The fitness, abbreviated as fit, is calculated in this manner $$fit = \frac{M-MC}{M}$$
$$0<fit<1$$
$fit$ is a number between 0 and 1 where $fit = 1$ is a perfect fit and $fit = 0$ is the worst fit.
The process of redistributing the data is repeated until a satisfying $fit$ is reached.
