\section{Hidden Markov Model}
A hidden Markov model (HMM) is used in this project as a mathematical model for the learning procedure. HMMs are typically used when reasoning over time, as they incorporate discrete time changes. Finding temporal patterns suits the needs for this project. A HMM, that approximates the real world, can be inferred, or \enquote{learned}. The components of such a HMM are described in detail below. Using this learned HMM, it is possible to solve many problems. In this project, HMMs are relevant for the problem of prediction. That is, given a sequence of observations up to time $t$ in the problem domain, what is the most likely observation in time $t+1$?

Other mathematical models could also have been chosen. If the focus in this project was finding the best possible way to predict user actions in the fastest, most precise way, multiple models would have to be compared based on real observation data.
The known, or observable, data in this project is what the sensors observe. 
We will now introduce the diagrams visually, mainly to illustrate how the models change over time. These diagrams are called trellis diagrams. The simplest form of a Markov model can be seen in \cref{fig:1stMarkovModel}. Here we can see the property that at any state in time $s_t$ the next discrete time future $s_{t+1}$ is only dependent on the current state $s_t$, and not on previous states. This is called the \emph{Markov property}.

\begin{figure}[htbp]
\centering
\begin{tikzpicture}
  %World States Nodes
  \node          (dots) [draw=none,  minimum width=1.25cm, minimum height=.75cm] {\LARGE \dots};
  \node[ellipse] (htp2) [draw=black, minimum width=1.25cm, minimum height=.75cm, right=of dots] {$s_{t-2}$};
  \node[ellipse] (htp1) [draw=black, minimum width=1.25cm, minimum height=.75cm, right=of htp2] {$s_{t-1}$};
  \node[ellipse] (ht)   [draw=black, minimum width=1.25cm, minimum height=.75cm, right=of htp1] {$s_t$};
  \node[ellipse] (htf1) [draw=black, minimum width=1.25cm, minimum height=.75cm, right=of ht] {$s_{t+1}$};

  %1. order transition lines
  \draw [->, to path={-| (\tikztotarget)}] (dots) edge[out=0,in=180] (htp2);
  \draw [->, to path={-| (\tikztotarget)}] (htp2) edge[out=0,in=180] (htp1);
  \draw [->, to path={-| (\tikztotarget)}] (htp1) edge[out=0,in=180] (ht);
  \draw [->, to path={-| (\tikztotarget)}] (ht) edge[out=0,in=180] (htf1);
\end{tikzpicture}
\caption[Trellis diagram for a simple Markov model]{The trellis diagram for a hidden Markov model with discrete time world state changes}\label{fig:1stMarkovModel}
\end{figure}

Even though these diagrams are good at illustrating the models and how they change over time, it is important to remember that these are not illustrating the exact models themselves, only how they change over time for a specific sequence of observations. The actual model could be illustrated with causal networks, which will be used later.

As it is not realistic to observe everything using sensors, HMMs have a concept of states that are hidden. These states represent what the state of the world is in reality, and is therefore not observable. A hidden state can emit an observable state of the world. In this project, this means that the hidden states are the true states of the home; all information needed for the user to take a choice on what to do next. This unobservable world then emits values to the sensors, that we can observe, creating the observable states called emission states. These are all distinct and can be emitted multiple times in a sequence of observations. See \cref{fig:2ndMarkovModel} for an example of a simple HMM. Note that a trellis diagram represents a sequence of observed state over time, we therefore make a distinction between emission states and observed states. Emission states are all states that can be emitted, the states of the model, and observed states are all states that have been emitted and observed. The important difference is that emission states cannot be the same, they are always distinct. Observed states can be equivalent, they are simply observed at different time steps.


We denote emission states as $E=\{e_1, \dots ,e_{M}\}|M = \text{number of emission states}$. Observed states as $\mathcal{O}=\{o_1, \dots , o_T\}|T = \text{number of observations}$.

\begin{figure}[htbp]
\centering
\begin{tikzpicture}
  %Hidden Nodes
  \node          (dots) [draw=none,  minimum width=1.25cm, minimum height=.75cm] {\LARGE \dots};
  \node[ellipse] (htp2) [draw=black, minimum width=1.25cm, minimum height=.75cm, right=of dots] {$x_{t-2}$};
  \node[ellipse] (htp1) [draw=black, minimum width=1.25cm, minimum height=.75cm, right=of htp2] {$x_{t-1}$};
  \node[ellipse] (ht)   [draw=black, minimum width=1.25cm, minimum height=.75cm, right=of htp1] {$x_t$};
  \node[ellipse] (htf1) [draw=black, minimum width=1.25cm, minimum height=.75cm, right=of ht] {$x_{t+1}$};

  %Emission states
  \node[ellipse] (etp1) [draw=black, minimum width=1.25cm, minimum height=.75cm, below=of htp1] {$e_{t-1}$};
  \node[ellipse] (etp2) [draw=black, minimum width=1.25cm, minimum height=.75cm, below=of htp2] {$e_{t-1}$};
  \node[ellipse] (et)   [draw=black, minimum width=1.25cm, minimum height=.75cm, below=of ht] {$e_t$};
  \node[ellipse] (etf1) [draw=black, minimum width=1.25cm, minimum height=.75cm, below=of htf1] {$e_{t+1}$};

  %Separator
  \coordinate (MW) at (0,-0.8);
  \node (HW) [above left=0ex of MW] {Hidden world $\uparrow$};
  \node (VW) [below left=0ex of MW] {Observable world $\downarrow$};
  \draw[dashed, draw=black] (-1,-0.8) -- (10.5,-0.8);
  %\draw[dashed] ($(htp2)!0.5!(etp2)$) -- ($(htf1)!0.5!(etf1)$);

  %Emission lines
  \draw[->, to path={-| (\tikztotarget)}] (htp1) edge[out=-90,in=90] (etp1);
  \draw[->, to path={-| (\tikztotarget)}] (htp2) edge[out=-90,in=90] (etp2);
  \draw[->, to path={-| (\tikztotarget)}] (ht) edge[out=-90,in=90] (et);
  \draw[->, to path={-| (\tikztotarget)}] (htf1) edge[out=-90,in=90] (etf1);

  %1. order lines
  \draw[->, to path={-| (\tikztotarget)}] (dots) edge[out=0,in=180] (htp2);
  \draw[->, to path={-| (\tikztotarget)}] (htp2) edge[out=0,in=180] (htp1);
  \draw[->, to path={-| (\tikztotarget)}] (htp1) edge[out=0,in=180] (ht);
  \draw[->, to path={-| (\tikztotarget)}] (ht) edge[out=0,in=180] (htf1);
\end{tikzpicture}
\caption[Trellis diagram for a simple Hidden Markov Model]{The trellis diagram for a simple hidden Markov model that assumes the Markov property}\label{fig:2ndMarkovModel}
\end{figure}

As described in \cref{sec:sampler}, the Markov property might not model the reality accurately. One could increase the number of states a state is dependent on in the past. The order of a HMM directly corresponds to how many states any state $s_t$ is dependent on. This is better illustrated, see \cref{fig:3rdMarkovModel}.

\begin{figure}[htbp]
\centering
\begin{tikzpicture}
  %Hidden Nodes
  \node          (dots) [draw=none,  minimum width=1cm, minimum height=.75cm] {\LARGE \dots};
  \node[ellipse] (htp2) [draw=black, minimum width=1cm, minimum height=.75cm, right=of dots] {$x_{t-2}$};
  \node[ellipse] (htp1) [draw=black, minimum width=1cm, minimum height=.75cm, right=of htp2] {$x_{t-1}$};
  \node[ellipse] (ht)   [draw=black, minimum width=1cm, minimum height=.75cm, right=of htp1] {$x_t$};
  \node[ellipse] (htf1) [draw=black, minimum width=1cm, minimum height=.75cm, right=of ht] {$x_{t+1}$};

  %Emission states
  \node[ellipse] (etp2) [draw=black, minimum width=1cm, minimum height=.75cm, below=of htp2] {$e_{t-2}$};
  \node[ellipse] (etp1) [draw=black, minimum width=1cm, minimum height=.75cm, below=of htp1] {$e_{t-1}$};
  \node[ellipse] (et)   [draw=black, minimum width=1cm, minimum height=.75cm, below=of ht] {$e_t$};
  \node[ellipse] (etf1) [draw=black, minimum width=1cm, minimum height=.75cm, below=of htf1] {$e_{t+1}$};

  %Emission lines
  \draw [->, to path={-| (\tikztotarget)}] (htp2) edge[out=-90,in=90] (etp2);
  \draw [->, to path={-| (\tikztotarget)}] (htp1) edge[out=-90,in=90] (etp1);
  \draw [->, to path={-| (\tikztotarget)}] (ht) edge[out=-90,in=90] (et);
  \draw [->, to path={-| (\tikztotarget)}] (htf1) edge[out=-90,in=90] (etf1);

  %1. order lines
  \draw [->, to path={-| (\tikztotarget)}] (dots) edge[out=0,in=180] (htp2);
  \draw [->, to path={-| (\tikztotarget)}] (htp2) edge[out=0,in=180] (htp1);
  \draw [->, to path={-| (\tikztotarget)}] (htp1) edge[out=0,in=180] (ht);
  \draw [->, to path={-| (\tikztotarget)}] (ht) edge[out=0,in=180] (htf1);

  %2. order lines
  \draw [->, to path={-| (\tikztotarget)}] (dots) edge[out=45,in=135] (htp2);
  \draw [->, to path={-| (\tikztotarget)}] (dots) edge[out=45,in=135] (htp1);
  \draw [->, to path={-| (\tikztotarget)}] (htp2) edge[out=45,in=135] (ht);
  \draw [->, to path={-| (\tikztotarget)}] (htp1) edge[out=45,in=135] (htf1);
\end{tikzpicture}
\caption[Trellis diagram for a 2nd order HMM]{A trellis diagram for a 2nd order HMM.}\label{fig:3rdMarkovModel}
\end{figure}

\Cref{fig:3rdMarkovModel} shows the trellis diagram for a 2nd order Markov model. Here, we can see that every state $s_t$ is dependent on two states in the past, $s_{t-1}$ and $s_{t-2}$, meaning that every state is not only dependent on what happened the time step before, violating the \emph{Markov property}. This can trivially be expanded to any \emph{n}th order Markov model. Every model we have looked at so far has been a 1st order Markov model. Any \emph{n}th order Markov model, where $n>1$, violates the Markov property. Many algorithms within this field assumes the Markov property, including the ones later used in this project. Any \emph{n}th order Markov model can be converted to a 1st order Markov model, thereby keeping the Markov property. This is, in this project, done by encoding the past, in form of the prior hidden states, in the hidden state.

On the basis of this, we can now find the specific hidden states. We introduce the term \emph{sample} that covers the current observable snapshot together with the history of snapshots $n$ steps back. The size of this $n$ will be discussed in \cref{sec:sampler}. This sample is used to find hidden states. A list of samples are created from an observation sequence of snapshots, further described in \cref{sec:sampler}. One could argue that this sample needs to be created from a history of hidden states, not snapshots, since it is these we depend on in the current state. A compromise was therefore made so that the samples, and thereby hidden states, are found from the observations and history of observations, on the reasoning that we cannot distinguish between two hidden states from anything else then the observations. A hidden state will therefore be created for every sample in the HMM to keep the model in 1st order and thereby keep the Markov property.

In a visual representation of a HMM a state is connected with a direction to other states with a certain probability. This denotes the probability of transitioning from one state to another. There are two different forms of transitions in such a model.

First, there is the hidden state transition from one state to another, here denoted as $a_{ij}$, meaning the transition from hidden state $x_i$ to hidden state $x_j$. It can also be described as the probability that if we know that the state is $x_i$ at time t, what is the probability that the next hidden state is $x_j$.

Secondly, we have the transition from a hidden state to an emission state. This is called emitting an emission state. It is notated as $b_{ij}$, meaning emitting emission state $e_j$ in hidden state $x_i$. This is associated with a certain probability.

Furthermore, we have the initial distribution. This denotes the probability distribution of any hidden state without a prior hidden state; the initial probability for being in hidden state $x_i$. This can essentially be described as the probability of starting in that state.

All of these types of transitions and probabilities can be described in matrices, which brings us to the formal definition of a HMM:

\begin{align*}
\theta = \{A,B,\pi\} &|\\
A &= \text{hidden state transition matrix}\\
B &= \text{emission matrix}\\
\pi &= \text{initial distribution}
\end{align*}

Here we can see that we have a matrix for each form of probability. This means that each matrix contains probabilities. The transition matrix $A$ is the matrix denoting the hidden state transition probability $P(X_t=x_j|X_{t-1}=x_i)$. The emission matrix $B$ denotes the emission probability, $P(E_t=e_j|X_t=x_j)$. We can also visually represent a HMM in a causal network, as can be seen in \cref{fig:HMMCausalNet}.

\begin{figure}[htbp]
\centering
\begin{tikzpicture}[->]
  %Hidden Nodes
  \node[circle, draw=black, minimum size=1cm] (x1) {$x_1$};
  \node[circle, draw=black, minimum size=1cm, node distance=3cm, right=of x1] (x2) {$x_2$};
  \node[circle, draw=black, minimum size=1cm, node distance=3cm, below=of x1] (x3) {$x_3$};
  \node[circle, draw=black, minimum size=1cm, node distance=3cm, below=of x2] (x4) {$x_4$};

  %Emission states
  \node[circle] (e11) [draw=black, minimum size=1cm, node distance=1.5cm, above=of x1] {$e_1$};
  \node[circle] (e12) [draw=black, minimum size=1cm, node distance=1.5cm, left=of x1] {$e_2$};
  \node[circle] (e21) [draw=black, minimum size=1cm, node distance=1.5cm, above=of x2] {$e_1$};
  \node[circle] (e22) [draw=black, minimum size=1cm, node distance=1.5cm, right=of x2] {$e_2$};
  \node[circle] (e31) [draw=black, minimum size=1cm, node distance=1.5cm, left=of x3] {$e_1$};
  \node[circle] (e32) [draw=black, minimum size=1cm, node distance=1.5cm, below=of x3] {$e_2$};
  \node[circle] (e41) [draw=black, minimum size=1cm, node distance=1.5cm, below=of x4] {$e_1$};
  \node[circle] (e42) [draw=black, minimum size=1cm, node distance=1.5cm, right=of x4] {$e_2$};

  \path
  %Emission lines
    (x1) edge[out=90,in=-90] node[rectangle,fill=white] {$b_{11}$} (e11)
    (x1) edge[out=180,in=0] node[rectangle,fill=white] {$b_{12}$} (e12)
    (x2) edge[out=90,in=-90] node[rectangle,fill=white] {$b_{21}$} (e21)
    (x2) edge[out=0,in=180] node[rectangle,fill=white] {$b_{22}$} (e22)
    (x3) edge[out=180,in=0] node[rectangle,fill=white] {$b_{31}$} (e31)
    (x3) edge[out=-90,in=90] node[rectangle,fill=white] {$b_{32}$} (e32)
    (x4) edge[out=-90,in=90] node[rectangle,fill=white] {$b_{41}$} (e41)
    (x4) edge[out=0,in=180] node[rectangle,fill=white] {$b_{42}$} (e42)

  %Transition lines
    (x1) edge[out=15,in=165] node[rectangle,fill=white] {$a_{12}$} (x2)
    (x2) edge[out=-165,in=-15] node[rectangle,fill=white] {$a_{21}$} (x1)
    (x2) edge[out=-75,in=75] node[rectangle,fill=white] {$a_{24}$} (x4)
    (x4) edge[out=105,in=-105] node[rectangle,fill=white] {$a_{42}$} (x2)
    (x4) edge[out=-165,in=-15] node[rectangle,fill=white] {$a_{43}$} (x3)
    (x3) edge[out=15,in=165] node[rectangle,fill=white] {$a_{34}$} (x4)
    (x3) edge[out=105,in=-105] node[rectangle,fill=white] {$a_{31}$} (x1)
    (x1) edge[out=-75,in=75] node[rectangle,fill=white] {$a_{13}$} (x3)

    (x1) edge[out=-30,in=120] node[rectangle,fill=white] {$a_{14}$} (x4)
    (x4) edge[out=150,in=-60] node[rectangle,fill=white] {$a_{41}$} (x1)
    (x3) edge[out=60,in=-150] node[rectangle,fill=white] {$a_{32}$} (x2)
    (x2) edge[out=-120,in=30] node[rectangle,fill=white] {$a_{23}$} (x3)

    (x1) edge [out=150,in=120,loop,looseness=15] node[rectangle,fill=white] {$a_{11}$} (x1)
    (x2) edge [out=60,in=30,loop,looseness=15] node[rectangle,fill=white] {$a_{22}$} (x2)
    (x3) edge [out=-120,in=-150,loop,looseness=15] node[rectangle,fill=white] {$a_{33}$} (x3)
    (x4) edge [out=-30,in=-60,loop,looseness=15] node[rectangle,fill=white] {$a_{44}$} (x4);
\end{tikzpicture}
\caption[A HMM represented as a causal network.]{A hidden Markov model, with four hidden states and two emission states, represented as a causal network.}\label{fig:HMMCausalNet}
\end{figure}

\Cref{fig:HMMCausalNet} represents a HMM with four hidden states and two emission states. The names on the arrows in the matrix (e.g. $a_{ij}$ and $b_{ij}$) represent entries in the two matrices, i.e. probabilities. We can see that every hidden state is connected to every hidden state (including itself) and that every hidden state can emit every emission state. This is not always the case in reality, since some hidden states could never directly reach other states and not every emission state could be emitted from every hidden state. This could be represented either as a sparse matrix or a matrix with some entries with the value 0. In essence, they are equivalent, since a connection that has a probability of 0 can never happen. This is just a case of how one represents \enquote{no connection}. Both of these representations pose a problem.

The learning algorithms for HMMs cannot learn the connections between states, meaning that if there is no connection to begin with, there never will be one in the future. This is a dangerous assumption to make, since we rarely have a complete understanding of the problem domain (after all, it is why we are trying to learn the hidden states) nor have a complete understanding of what each state exactly represents. In some cases, a complete understanding of these things\kanote{things?} is not necessary, some things are simply impossible. This cannot be said about this project. Firstly, all hidden states can emit all emission states, since we have a world with unreliable sensors, and what we think is an impossible transition at a certain time could simply be faulty sensors' way of representing it\kanote{I have read this many times and still have no idea what the point, you(we) are trying to make, is}. Furthermore, addressing the transitions between hidden states, the hidden states are partly based on the user's memory and how the user thinks. This can change from one state to another at will, even if the transition is physically impossible\kanote{same with this point}. We assume that the user remembers the events in the past, as they happened, but since a user can forget, see reality differently or our sensors observe wrongly, we leave all connections in the model and thereby making it able to accommodate changes and unreliability.

In the formal definition of HMMs we also had $\pi$, a matrix denoting the initial hidden state probability distribution, $P(X_1=x_i)$. Until now we have only illustrated models with relative time, but the initial probabilities give us the notion that there is an absolute time, starting at time 1 with probabilities denoted in this table. This is needed, since any observation sequence must have a starting point, and is going to become very important later, when we will learn and reason about the model. We can now expand the trellis diagrams with the notion of a starting point as can be seen in \cref{fig:4thMarkovModel}.

\begin{figure}[htbp]
\centering
\begin{tikzpicture}
  %Hidden Nodes
  \node[ellipse] (h1)   [draw=black, minimum width=1cm, minimum height=.75cm] {$x_1$};
  \node[ellipse] (h2)   [draw=black, minimum width=1cm, minimum height=.75cm, right=of h1] {$x_2$};
  \node          (dots) [draw=none,  minimum width=1cm, minimum height=.75cm, right=of h2] {\LARGE \dots};
  \node[ellipse] (htp1) [draw=black, minimum width=1cm, minimum height=.75cm, right=of dots] {$x_{t-1}$};
  \node[ellipse] (ht)   [draw=black, minimum width=1cm, minimum height=.75cm, right=of htp1] {$x_t$};
  \node[ellipse] (htf1) [draw=black, minimum width=1cm, minimum height=.75cm, right=of ht] {$x_{t+1}$};

  %Emission states
  \node[ellipse] (e1)   [draw=black, minimum width=1cm, minimum height=.75cm, below=of h1] {$e_1$};
  \node[ellipse] (e2)   [draw=black, minimum width=1cm, minimum height=.75cm, below=of h2] {$e_2$};
  \node[ellipse] (etp1) [draw=black, minimum width=1cm, minimum height=.75cm, below=of htp1] {$e_{t-1}$};
  \node[ellipse] (et)   [draw=black, minimum width=1cm, minimum height=.75cm, below=of ht] {$e_t$};
  \node[ellipse] (etf1) [draw=black, minimum width=1cm, minimum height=.75cm, below=of htf1] {$e_{t+1}$};

  %Emission lines
  \draw [->, to path={-| (\tikztotarget)}] (h1) edge[out=-90,in=90] (e1);
  \draw [->, to path={-| (\tikztotarget)}] (h2) edge[out=-90,in=90] (e2);
  \draw [->, to path={-| (\tikztotarget)}] (htp1) edge[out=-90,in=90] (etp1);
  \draw [->, to path={-| (\tikztotarget)}] (ht) edge[out=-90,in=90] (et);
  \draw [->, to path={-| (\tikztotarget)}] (htf1) edge[out=-90,in=90] (etf1);

  %1. order lines
  \draw [->, to path={-| (\tikztotarget)}] (h1) edge[out=0,in=180] (h2);
  \draw [->, to path={-| (\tikztotarget)}] (h2) edge[out=0,in=180] (dots);
  \draw [->, to path={-| (\tikztotarget)}] (dots) edge[out=0,in=180] (htp1);
  \draw [->, to path={-| (\tikztotarget)}] (htp1) edge[out=0,in=180] (ht);
  \draw [->, to path={-| (\tikztotarget)}] (ht) edge[out=0,in=180] (htf1);
\end{tikzpicture}
\caption[Absolute and relative time trellis diagram for a HMM]{An absolute and relative time trellis diagram for a 1st order HMM}\label{fig:4thMarkovModel}
\end{figure}

Now that we have a complete model of the problem domain, we can move on to the two tasks, this project will use this model for; learning and prediction.

\subsection{Learning}
Learning is the task of determining the probabilities of the transitions in the HMM. It is noteworthy that we cannot reliably learn the states and probabilities of the HMM. Therefore we, in the previous section, discussed how to determinate the states. We will now look into how to determinate the probabilities between the states.

For learning, this project uses the Baum-Welch algorithm\kanote{should have a source}, a specific implementation of the forwards-backwards algorithm\kanote{should have a source}.

Given the model $\theta = \{A, B, \pi\}$ and a sequence of observations $\mathcal{O}$, the algorithm tries to find the parameters $A$, $B$ and $\pi$, which maximise the probability of the observations given as input, that is $P(Y | \theta)$.

These new parameters can be calculated in the following way\cite{hmmIntroduction}.

\begin{equation*}
\pi_i = \sum\limits_{i=0}^{N-1} \sum\limits_{j=0}^{N-1} \gamma_0(j)
\end{equation*}

\begin{equation*}
a_{ij} = \frac{\sum\limits_{t=0}^{T-2} \gamma_t(i, j)}{ \sum\limits_{t=0}^{T-2} \gamma_t(i) }
\end{equation*}

\begin{equation*}
b_j(k)
\end{equation*}

$\xi_t (i, j)$ is the probability of being in state $x_i$ at time t and transiting to state $x_j$ at
time t + 1.

\subsection{Time as a sensor}
Another possible property to include in each snapshot is time, but just using linear time\footnote{e.g. time from to Unix Epoch\cite{unix_epoch}} as a feature of the state will not benefit the model, since two states will never equivalent by linear time. But if we instead use divisions of this time, we can consider two instances of time as the same, e.g. the hour of the day, the day of the week. Now the learner can learn on these features if relevant or not for the users pattern. E.g an user always does the laundry at around 12:00 o'clock on Monday, for this pattern, the month and year divisions will be consider as irrelevant for the behavioral pattern. These time formats should be found prior to implementation of the system and be based on studies on human perceptions of time. Figuring if a division of time is relevant on a pattern and the system only has two weeks of samples, then nothing can be said about the day of the week yet, since there are only instances of repeating days.\\
An implementation of these time divisions would act as any other sensor in the system. It was decided that the variance of the sensors is already sufficient for illustrating the concept behind the project. Since these time divisions take considerably longer to find, and are more error prone compared to other sensors, it was chosen to delimit the project from this consideration.

\subsection{Prediction}\label{sub:Prediction}
The task of predicting is done after the model has been learned. This is the task of predicting, given list of observations $\{o_1,\dots,o_t\}$ and a model, what the most likely observation to be emitted in the next time step $x_{t+1}$ is. This can be done, partly, via the Viterbi algorithm\kanote{should have a source}. From a sequence of observations, the Viterbi algorithm can find the most probable sequence of hidden states, that caused this list of observations to occur, i.e. what sequence of hidden states $\{x_1,\dots,x_t\}$ is most probable to have emitted the observation sequence.

From this we can then predict what is most likely going to be the next hidden state, and then from this, what is most likely going to be emitted. The whole point of doing this is that we can now look at the difference in what is currently true in the problem domain, and what is most likely going to be true next. From this we can find out if we can emulate any of this, and if the probability of what is going to happen next is high enough, i.e. our confidence of what is going to happen next, we can emulate it. This means that the system does the action, which the user would do next, before the user has to.
