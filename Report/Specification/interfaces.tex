\section{User Interfaces}\label{sec:userInterfaces}
There are two kinds of user interaction in the system: passive and active interaction.

\subsection{Passive User Interaction}
Passive user interactions are those interactions that the users make with the environment that are silently monitored by the system to infer some emerging behaviour of the user. Examples of passive interactions are: \enquote{the user turns on the spotlight right after turning on the TV}, \enquote{the user turns on the coffee machine at 6:30}.

\subsection{Active User Interaction}
Active interactions are interactions that the user consciously has with the system. Examples of such interactions are: \enquote{the user tells the system that the coffee machine should not be turned on at 6:30 in the weekends}, \enquote{the user informs the system that the home will be vacant the next week}.

\subsection{Design of User Interface}
As stated in \cref{sec:requirements}, the system should be as invisible to the user as possible. This means that passive user interaction is to be preferred whenever possible.

\subsubsection{Informing the System of Wrong Actions}
\label{subs:informingTheSystem}
}

The system has to gradually learn which actions suit the user the best. To learn this, the system has to have a fitness function, in order to evaluate how well its performed actions were. The best input for such a fitness function is the user's opinion. However, this function cannot extract the input it needs from passive user interaction. The user has to actively interact with the system, telling the system how appropriate its actions were. Therefore, a mix of active and passive interaction is needed between the user and the system.

To reduce active user interaction, the user should only have to inform the system, when it has made a mistake. The interface could also be able to inform the system, when it has made a correct action, but requiring the user to interact with the system too often is distracting for the user. Therefore, if an action is not marked as wrong, it is assumed to be correct. Furthermore, the system should aim at avoiding wrong actions as much as possible. This means that the system should be conservative when performing actions, so that before the system gets confident enough to start performing an action, it should have acquired a significant number of observations of that action.

One way the user could inform the system of a mistake, is by reversing the action the system performed badly. For example, if the system wrongly turned off the light in the bathroom, the user would naturally turn on the light again. This would give the system an indication that its action was wrong. This is a good way for the user to interact with the system, as it feels natural for the user. However, there are problems with this approach. For example, if the system wrongly turns on the light in the bedroom, but the user first notices this 30 minutes later, and then turns off the light. Because the user does not immediately notice the wrong action, it is ambiguous for the system whether the whole action of turning the light on was wrong, or that it was correct to turn the light on, but to only leave it on for 30 minutes.

The best user experience is by having the user reverse the wrong action of the user, but in cases where this is not possible, an alternative interface is needed. One possible solution is a graphical user interface that displays all actions the system has made. The user can then choose actions and mark them as wrong. In contrast to the system inferring that an action was wrong because the user reverted it, as described above, this way of informing the system is unambiguous. However this method of user input is also less convenient for the user.

\subsubsection{Visualising System Knowledge}

As discussed in \cref{sec:interviewReports}, one of the problems of the Nest system was that the user could not reason about the actions of the system. That is, they would not know why an action was performed. To alleviate this problem, the knowledge of the system should be transparent. A solution would be to visually represent the knowledge of the system. \Cref{subs:informingTheSystem} mentioned a graphical user interface for displaying all actions the system has made. This can be extended to also include why a given action was made. For example, the interface could display the action \enquote{light turned on in living room at 21:30}. If the user clicked on this action, the system would display the reasoning behind this action. In this case, it could be: \enquote{The light intensity in the room was below 10 lux}.
